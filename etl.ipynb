{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# ETL Processes\n",
    "Use this notebook to develop the ETL process for each of your tables before completing the `etl.py` file to load the whole datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import psycopg2\n",
    "\n",
    "import pandas as pd\n",
    "from sql_queries import *"
   ]
  },
  {
   "source": [
    "conn = psycopg2.connect(\"host=127.0.0.1 user=postgres password=nubank\")\n",
    "conn.set_session(autocommit=True)\n",
    "cur = conn.cursor()"
   ],
   "cell_type": "code",
   "metadata": {
    "editable": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ObjectInUse",
     "evalue": "database \"nubank\" is being accessed by other users\nDETAIL:  There are 3 other sessions using the database.\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mObjectInUse\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-da260512008f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DROP DATABASE IF EXISTS nubank\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CREATE DATABASE nubank WITH ENCODING 'utf8' TEMPLATE template0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# close connection to default database\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mObjectInUse\u001b[0m: database \"nubank\" is being accessed by other users\nDETAIL:  There are 3 other sessions using the database.\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"DROP DATABASE IF EXISTS nubank\")\n",
    "cur.execute(\"CREATE DATABASE nubank WITH ENCODING 'utf8' TEMPLATE template0\")\n",
    "\n",
    "# close connection to default database\n",
    "conn.close()    \n",
    "    \n",
    " # connect to sparkify database\n",
    "conn = psycopg2.connect(\"host=127.0.0.1 dbname=nubank user=postgres password=nubank\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "source": [
    "conn = psycopg2.connect(\"host=127.0.0.1 dbname=nubank user=postgres password=nubank\")\n",
    "cur = conn.cursor()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in drop_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "\n",
    "for query in create_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('fact_movements_table',), ('costumers_table',), ('d_week_table',), ('accounts_table',), ('city_table',), ('customers_table',), ('country_table',), ('d_month_table',), ('d_time_table',), ('d_weekday_table',), ('d_year_table',), ('pix_movements_table',), ('state_table',), ('transfer_ins_table',), ('transfer_outs_table',)]\n"
     ]
    }
   ],
   "source": [
    "#VERIFY THE DB TABLES\n",
    "cur.execute(\"select relname from pg_class where relkind='r' and relname !~ '^(pg_|sql_)';\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_function(data, query):\n",
    "        for i, row in data.iterrows():\n",
    "                cur.execute(query, list(row))\n",
    "        conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Process table data\n",
    "In this first part, you'll perform ETL on the tables"
   ]
  },
  {
   "source": [
    "### Insert data in accounts_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_df = pd.read_csv(\"./tables/tables/accounts_table.csv\")\n",
    "insert_function(accounts_df, accounts_table_insert)"
   ]
  },
  {
   "source": [
    "### Insert data in city_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "city_df = pd.read_csv(\"./tables/tables/city_table.csv\")\n",
    "city_df = city_df[['city_id','city','state_id']]\n",
    "insert_function(city_df, city_table_insert)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 7,
   "outputs": []
  },
  {
   "source": [
    "### Insert data in customers_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "customers_df = pd.read_csv(\"./tables/tables/customers_table.csv\")\n",
    "customers_df.head()\n",
    "insert_function(customers_df, customers_table_insert)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 8,
   "outputs": []
  },
  {
   "source": [
    "### Insert data in country_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df = pd.read_csv(\"./tables/tables/country_table.csv\")\n",
    "country_df = country_df[[\"country_id\", \"country\"]]\n",
    "insert_function(country_df, country_table_insert)"
   ]
  },
  {
   "source": [
    "### Insert data in d_month_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_month_table_df = pd.read_csv(\"./tables/tables/d_month_table.csv\")\n",
    "insert_function(d_month_table_df, d_month_table_insert)"
   ]
  },
  {
   "source": [
    "### Insert data in d_time_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_time_table_df = pd.read_csv(\"./tables/tables/d_time_table.csv\")\n",
    "tmp_df = \"./tables/tables/tmp.csv\"\n",
    "d_time_table_df.to_csv(tmp_df,index=False , header=False)\n",
    "f = open(tmp_df, 'r')\n",
    "cur.copy_from(f, \"d_time_table\", sep=\",\")\n",
    "conn.commit()"
   ]
  },
  {
   "source": [
    "### Insert data in d_week_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_week_table_df = pd.read_csv(\"./tables/tables/d_week_table.csv\")\n",
    "insert_function(d_week_table_df, d_week_table_insert)"
   ]
  },
  {
   "source": [
    "### Insert data in d_weekday_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_weekday_table_df = pd.read_csv(\"./tables/tables/d_weekday_table.csv\")\n",
    "insert_function(d_weekday_table_df, d_weekday_table_insert)"
   ]
  },
  {
   "source": [
    "### Insert data in d_year_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_year_table_df = pd.read_csv(\"./tables/tables/d_year_table.csv\")\n",
    "insert_function(d_year_table_df, d_year_table_insert)"
   ]
  },
  {
   "source": [
    "### Insert data in state_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_table_df = pd.read_csv(\"./tables/tables/state_table.csv\")\n",
    "state_table_df = state_table_df[[\"state_id\", \"state\", \"country_id\"]]\n",
    "insert_function(state_table_df, state_table_insert)"
   ]
  },
  {
   "source": [
    "### Insert data in pix_movements_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_movements_table_df = pd.read_csv(\"./tables/tables/pix_movements_table.csv\")\n",
    "tmp_df = \"./tables/tables/tmp.csv\"\n",
    "pix_movements_table_df.to_csv(tmp_df,index=False , header=False)\n",
    "f = open(tmp_df, 'r')\n",
    "cur.copy_from(f, \"pix_movements_table\", sep=\",\")\n",
    "conn.commit()"
   ]
  },
  {
   "source": [
    "### Insert data in transfer_ins_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_ins_table_df = pd.read_csv(\"./tables/tables/transfer_ins_table.csv\")\n",
    "tmp_df = \"./tables/tables/tmp.csv\"\n",
    "transfer_ins_table_df.to_csv(tmp_df,index=False , header=False)\n",
    "f = open(tmp_df, 'r')\n",
    "cur.copy_from(f, \"transfer_ins_table\", sep=\",\")\n",
    "conn.commit()"
   ]
  },
  {
   "source": [
    "### Insert data in transfer_outs_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_outs_table_df = pd.read_csv(\"./tables/tables/transfer_outs_table.csv\")\n",
    "tmp_df = \"./tables/tables/tmp.csv\"\n",
    "transfer_outs_table_df.to_csv(tmp_df,index=False , header=False)\n",
    "f = open(tmp_df, 'r')\n",
    "cur.copy_from(f, \"transfer_outs_table\", sep=\",\")\n",
    "conn.commit()"
   ]
  },
  {
   "source": [
    "### Insert data in fact_movements_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from_pix_df = pix_movements_table_df.join(accounts_df.set_index('account_id'), on='account_id',rsuffix=\"p_\")\n",
    "from_in_df = transfer_ins_table_df.join(accounts_df.set_index('account_id'), on='account_id',rsuffix=\"in_\")\n",
    "from_out_df = transfer_outs_table_df.join(accounts_df.set_index('account_id'), on='account_id',rsuffix=\"out_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_pix_df[\"in_or_out\"].replace({\"pix_out\": \"out\", \"pix_in\": \"in\"}, inplace=True)\n",
    "from_pix_df.insert(3,'type', 'pix')\n",
    "from_pix_df = from_pix_df[['id', 'account_id','customer_id','in_or_out','type' , 'pix_amount','pix_requested_at','pix_completed_at','status' ]]\n",
    "from_pix_df = from_pix_df.rename(columns={'pix_amount': 'amount', 'pix_requested_at': 'transaction_requested_at', 'pix_completed_at': 'transaction_completed_at'})\n",
    "from_in_df.insert(3,'in_or_out', 'in')\n",
    "from_out_df.insert(3,'in_or_out', 'out')\n",
    "from_in_df.insert(3,'type', 'transfer_in')\n",
    "from_out_df.insert(3,'type', 'transfer_out')\n",
    "\n",
    "from_in_df = from_in_df[['id', 'account_id','customer_id','in_or_out','type' , 'amount','transaction_requested_at','transaction_completed_at','status' ]]\n",
    "from_out_df = from_out_df[['id', 'account_id','customer_id','in_or_out','type' , 'amount','transaction_requested_at','transaction_completed_at','status' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_movements_table = from_pix_df.append([from_in_df, from_out_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = \"./tables/tables/tmp.csv\"\n",
    "fact_movements_table.to_csv(tmp_df,index=False , header=False)\n",
    "f = open(tmp_df, 'r')\n",
    "cur.copy_from(f, \"fact_movements_table\", sep=\",\")\n",
    "conn.commit()"
   ]
  },
  {
   "source": [
    "### Close connection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "source": [
    "# Answering the questions: "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. Create a SQL query to help Jane retrieving the monthly balance of all accounts (this query should be made using the warehouse structure before the changes you propose on 2.)\n",
    "\n",
    "Your colleague Jane Hopper, the analyst in charge of analysing customer behaviour, who directly\n",
    "consumes data from the Data Warehouse Environment, needs to get all the account's monthly\n",
    "balances between Jan/2020 and Dec/2020. She wasn't able to do it alone, and asked for your help.\n",
    "Add to your resolution the SQL query used to retrieve the data needed (the necessary tables in csv\n",
    "format were sent along with this pdf, on folder tables/). Feel free to use the dialect of your choice,\n",
    "but please specify the SQL engine.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Resolution:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Developing the query to Account Monthly Balance\n",
    "\n",
    "The original table schema has three tables that contain movements in the costumers accounts, so in order to help Jane I need to put it all together and create the expected columns in the figure bellow.\n",
    "\n",
    "![](./images/balance_table.jpg)\n",
    "\n",
    "Note: In the image above the column costumer is present, but Jane want to know the account balance so to do this the account_id column will be used insteade costumer column.\n",
    "\n",
    "\n",
    "1. Using the `UNION ALL` combined with `SELECT` the result put all the data contained in the tables together one appending the tables creating a subquery.\n",
    "2. We need to create the columns with INs and OUTs, in the pix transactions we have to distinct between the IN and OUT movements, where I used `CASE` to make this distinction using the column `in_or_out` present in the pix table:\n",
    "\n",
    "\n",
    "```sql \n",
    "        CASE in_or_out WHEN 'pix_out' then pix_amount ELSE 0 END as SAIDA,\n",
    "        CASE in_or_out WHEN  'pix_in' then pix_amount ELSE 0 END as ENTRADA\n",
    "``` \n",
    "In the tables of usual transactions the distinction was not necessary, because each table contain one specific kind of transaction, so I returned the amount in the column that represents the kind of transaction and 0(zero) in the other column, like above:\n",
    "\n",
    "In table:\n",
    "```sql\n",
    "        SELECT account_id,\n",
    "        0 AS SAIDA, \n",
    "        amount as ENTRADA,\n",
    "```\n",
    "\n",
    "Out table:\n",
    "```sql\n",
    "        SELECT account_id,\n",
    "        amount as SAIDA,\n",
    "        0 AS ENTRADA,\n",
    "```\n",
    "\n",
    "3. To get the mounth column, first I converted the timestamp that contains the date when the transaction was completed to a datetime format and after with `DATE_PART` specifing month as my part of interest, I got the month:\n",
    "\n",
    "```sql\n",
    "        DATE_PART('month', to_timestamp(CAST(transaction_completed_at as numeric)/1000)) MES\n",
    "```\n",
    "\n",
    "4. The `WHERE` clause is filtering the transactions that were completed and occured between JAN/2020 and DEC/2020:\n",
    "\n",
    "```sql\n",
    "        WHERE (status = 'completed') AND (DATE_PART('year', to_timestamp(CAST(pix_completed_at as numeric)/1000))  = 2020)\n",
    "```\n",
    "\n",
    "5. With the data returned in the subquery `transactions` is necessary to sum all the In and all the Out movements separately grouping then by account_id and month, after the monthly balance is a result of the Ins - Outs for each month and account. All this columns were rounded with two decimal places that is enough when we talk about monetary values.\n",
    "\n",
    "\n",
    "Select statement:\n",
    "```sql\n",
    "        SELECT CAST(mes AS INT), account_id,\n",
    "        ROUND(CAST(sum(entrada) AS NUMERIC),2) AS entradas_total,\n",
    "        ROUND(CAST(SUM(saida) AS NUMERIC),2) as saidas_total,\n",
    "        ROUND(CAST((sum(entrada) - SUM(saida))AS NUMERIC),2) as balanco\n",
    "\n",
    "```\n",
    "\n",
    "Group by and Order by statement:\n",
    "\n",
    "```sql\n",
    "        GROUP BY mes, account_id\n",
    "        ORDER BY account_id, mes\n",
    "\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Importing the `create_engine` from `sqlalchemy` to create the connection to our Postgres database."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://postgres:nubank@127.0.0.1/nubank')"
   ]
  },
  {
   "source": [
    "### Using the `pd.read_sql` and the previous created `engine` to execute our SQL query and create a pandas dataframe with the result."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time to query execution:  0.9935104846954346\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "balance = pd.read_sql('''\n",
    "SELECT CAST(mes AS INT), \n",
    "account_id,\n",
    "ROUND(CAST(sum(entrada) AS NUMERIC),2) AS entradas_total,\n",
    "ROUND(CAST(SUM(saida) AS NUMERIC),2) as saidas_total,\n",
    "ROUND(CAST((sum(entrada) - SUM(saida))AS NUMERIC),2) as balanco\n",
    "FROM (  SELECT account_id, \n",
    "        CASE in_or_out WHEN 'pix_out' then pix_amount ELSE 0 END as SAIDA, \n",
    "        CASE in_or_out WHEN  'pix_in' then pix_amount ELSE 0 END as ENTRADA,\n",
    "        DATE_PART('month', to_timestamp(CAST(pix_completed_at as numeric)/1000)) AS MES\n",
    "        FROM pix_movements_table\n",
    "        WHERE (status = 'completed') AND (DATE_PART('year', to_timestamp(CAST(pix_completed_at as numeric)/1000))  = 2020)\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        SELECT account_id,\n",
    "        0 AS SAIDA, \n",
    "        amount as ENTRADA,\n",
    "        DATE_PART('month', to_timestamp(CAST(transaction_completed_at as numeric)/1000)) AS MES\n",
    "        FROM transfer_ins_table\n",
    "        WHERE (status = 'completed') AND (DATE_PART('year', to_timestamp(CAST(transaction_completed_at as numeric)/1000)) = 2020)\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        SELECT account_id,\n",
    "        amount as SAIDA,\n",
    "        0 AS ENTRADA,\n",
    "        DATE_PART('month', to_timestamp(CAST(transaction_completed_at as numeric)/1000)) AS MES\n",
    "        FROM transfer_outs_table\n",
    "        WHERE (status = 'completed') AND (DATE_PART('year', to_timestamp(CAST(transaction_completed_at as numeric)/1000)) = 2020)) as transactions\n",
    "GROUP BY mes, account_id\n",
    "ORDER BY mes, account_id\n",
    "\n",
    "''', engine)\n",
    "end = time.time()\n",
    "print(\"Time to query execution: \",end - start)"
   ]
  },
  {
   "source": [
    "### Looking into the `balance` dataframe to see the result of our query"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    mes         account_id  entradas_total  saidas_total  balanco\n",
       "0     1   2569200459575096         6622.15       1826.30  4795.85\n",
       "1     1   2572645138169593         3314.38       1467.31  1847.07\n",
       "2     1   2969674447809961         9013.62       3569.48  5444.14\n",
       "3     1   5756422114496119         2926.91       2170.55   756.36\n",
       "4     1   5763135580788529         6460.05      11030.11 -4570.06\n",
       "5     1   6731171884115662         9660.82       5316.85  4343.97\n",
       "6     1   6754575908057409         5780.74          0.00  5780.74\n",
       "7     1   6759884497455352         4308.37       1542.19  2766.18\n",
       "8     1   7106839639082916         3062.88       1402.65  1660.23\n",
       "9     1   7399497589386025         1319.22          0.00  1319.22\n",
       "10    1   8390860978077109         7559.18      17064.75 -9505.57\n",
       "11    1   9682140161583058         6125.78      11087.89 -4962.11\n",
       "12    1  11972044772734216         4480.96        759.50  3721.46\n",
       "13    1  14823956517654278        11269.08       4940.66  6328.42\n",
       "14    1  14960923507500004         2365.23       4424.75 -2059.52\n",
       "15    1  16488801170250194         1382.95          0.00  1382.95\n",
       "16    1  17010643349938116         1446.35       1812.93  -366.58\n",
       "17    1  17352812883658752         8757.83      13354.52 -4596.69\n",
       "18    1  18661351842096488         1148.46       5642.76 -4494.30\n",
       "19    1  21312345113145264        10272.73       2697.03  7575.70"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mes</th>\n      <th>account_id</th>\n      <th>entradas_total</th>\n      <th>saidas_total</th>\n      <th>balanco</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2569200459575096</td>\n      <td>6622.15</td>\n      <td>1826.30</td>\n      <td>4795.85</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2572645138169593</td>\n      <td>3314.38</td>\n      <td>1467.31</td>\n      <td>1847.07</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>2969674447809961</td>\n      <td>9013.62</td>\n      <td>3569.48</td>\n      <td>5444.14</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>5756422114496119</td>\n      <td>2926.91</td>\n      <td>2170.55</td>\n      <td>756.36</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5763135580788529</td>\n      <td>6460.05</td>\n      <td>11030.11</td>\n      <td>-4570.06</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>6731171884115662</td>\n      <td>9660.82</td>\n      <td>5316.85</td>\n      <td>4343.97</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>6754575908057409</td>\n      <td>5780.74</td>\n      <td>0.00</td>\n      <td>5780.74</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>6759884497455352</td>\n      <td>4308.37</td>\n      <td>1542.19</td>\n      <td>2766.18</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>7106839639082916</td>\n      <td>3062.88</td>\n      <td>1402.65</td>\n      <td>1660.23</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>7399497589386025</td>\n      <td>1319.22</td>\n      <td>0.00</td>\n      <td>1319.22</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1</td>\n      <td>8390860978077109</td>\n      <td>7559.18</td>\n      <td>17064.75</td>\n      <td>-9505.57</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1</td>\n      <td>9682140161583058</td>\n      <td>6125.78</td>\n      <td>11087.89</td>\n      <td>-4962.11</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1</td>\n      <td>11972044772734216</td>\n      <td>4480.96</td>\n      <td>759.50</td>\n      <td>3721.46</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1</td>\n      <td>14823956517654278</td>\n      <td>11269.08</td>\n      <td>4940.66</td>\n      <td>6328.42</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1</td>\n      <td>14960923507500004</td>\n      <td>2365.23</td>\n      <td>4424.75</td>\n      <td>-2059.52</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1</td>\n      <td>16488801170250194</td>\n      <td>1382.95</td>\n      <td>0.00</td>\n      <td>1382.95</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1</td>\n      <td>17010643349938116</td>\n      <td>1446.35</td>\n      <td>1812.93</td>\n      <td>-366.58</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1</td>\n      <td>17352812883658752</td>\n      <td>8757.83</td>\n      <td>13354.52</td>\n      <td>-4596.69</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1</td>\n      <td>18661351842096488</td>\n      <td>1148.46</td>\n      <td>5642.76</td>\n      <td>-4494.30</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1</td>\n      <td>21312345113145264</td>\n      <td>10272.73</td>\n      <td>2697.03</td>\n      <td>7575.70</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "balance.head(20)"
   ]
  },
  {
   "source": [
    "## 2. Improve the data warehouse architecture and justify your changes\n",
    "\n",
    "Imagine now that you could remodel the data warehouse environment freely, keeping in mind that\n",
    "Nubank is always evolving with new products (Whatsapp Payments, PIX, phone recharge, etc) and it\n",
    "is also expanding to new countries, so our data warehouse needs to accommodate all these\n",
    "incoming changes. Which modifications would you propose and why? Remember to consider that\n",
    "other analysts will be using the same structure, so it should be as clear as possible. Feel free to\n",
    "change, remove or add tables/fields to generate a better database design"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Resolution:\n",
    "\n",
    "To do this remodeling in the data warehouse is necessary first to answer the question: **What are the fundamental goals of the data warehousing ?** So let`s talk about this.\n",
    "\n",
    "**A few bussiness analysts big problems:**\n",
    "\n",
    "- We have data, but we can`t access it.\n",
    "- We need access the data easily,\n",
    "- We need the right numbers to make the right decisions.\n",
    "\n",
    "**Based on this problems the main goals to build a data warehouse could be:**\n",
    "\n",
    "- Make the data easily accessible.\n",
    "- Show consistently information.\n",
    "- Need to be adaptable to changes.\n",
    "- Fast data aquisition.\n",
    "- Trustworthy data.\n",
    "- Data security.\n",
    "\n",
    "After this small introduction is expected that the more important aspects of a data warehouse are cleared. If not we can make it simple: We need to provide the data contained in the tables as clearly, easily and with the fastest performance as possible. To do this I will use the **Dimensional modeling** that is a very used technique for presenting analytic data.\n",
    "\n",
    "### Dimensional Modeling\n",
    "\n",
    "Dimensional modeling is used to make tha data arrangement simple, we need it simple to the users can easily understand the data, it needs to be friendly user, the dimensional models are diferent from the realtional or 3NF(third normal form) where the focus is in remove data redundances.\n",
    "\n",
    "To make this remodeling I will use A **Star Schema** model, where we have a **fact table** connectes to **dimensional tables**. This is the name because it can remember you a star, like in the image bellow.\n",
    "\n",
    "![](./images/star.jpg)\n",
    "\n",
    "This kind of schema was choiced by me because of its simplicity during the modeling and due its format the querys are smaller than in another models making it easy to access the data contained in the tables.\n",
    "\n",
    "\n",
    "### Fact table\n",
    "\n",
    "The fact table is responsable for storage the events occured in the bussiness process, in this case our fact table will store all the transactions ocurred in the accounts, including pix transactions. The field type was included in the new table, this field is responsable to store the transaction method that the user used in this case ti could be pix and standard transfers, but like in the file provided for nubank it can suporte another kind of methods, like whatsapp, phone recharge and others. The field in or out was included to make the distinction between the transactions that were made to the account(money arriving) or from the account(money leaving). The customer_id was included to make the connection with the costumer dimension table.\n",
    "\n",
    "![](./images/fact_table.jpg)\n",
    "\n",
    "\n",
    "### Dimensional tables\n",
    "\n",
    "The dimensional tables are responsable for the descriptive concept, it contains the textual data needed to describe the event occured in the process. Each dimensional table is connected with the fact table using a primary key. In our case are necessary three dimensional tables that describe the transaction process, the table with customers informations, the table with accounts information and the table with time information. I believe that with this three table we can describe the transaction process very clearly and easier than before.\n",
    "\n",
    "**Customer dimensional table:** In this table all the data related the customer is stored.\n",
    "\n",
    "![](./images/dim_customer.jpg)\n",
    "\n",
    "**Accounts dimensional table:** This table have all the data related the accounts. It was not changed.\n",
    "\n",
    "![](./images/dim_accounts.jpg)\n",
    "\n",
    "**Time dimensional table:** In this table is the data responsable for describe the time, like year, month, day etc.\n",
    "\n",
    "![](./images/dim_time.jpg)\n",
    "\n",
    "### Final schema\n",
    "\n",
    "Puting all the described tables above together with the respectives conections between fact and dimension tables we can see how simple the schema has become. A connection between accounts table and customers table was necessary in order to return the data related from customer and his account.\n",
    "\n",
    "\n",
    "![](./images/final_schema.jpg)\n",
    "\n",
    "\n",
    "Note: Part of the definitions used to make this data modeling were based on the book [The Data Warehouse Toolkit: The Definitive Guide to Dimensional Modeling](https://www.oreilly.com/library/view/the-data-warehouse/9781118530801/)\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Comparing performance\n",
    "\n",
    "Using the Jane`s case where she wants to get the balance from the accounts, with the old data warehouse schema the query used is performed in approximately 1 second, with the new schema the new query was performed in approximately 0,66 second. With this we reduced the time to execute the query in 34%, in bgi volume os transactions this reduction becomes very significant."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "start = time.time()\n",
    "balance_new = pd.read_sql('''SELECT mes, account_id, SUM(ENTRADA) AS entradas_total, SUM(SAIDA) AS saidas_total, (SUM(ENTRADA)-SUM(SAIDA)) as balanco\n",
    "                                FROM (SELECT account_id, \n",
    "                                        CASE in_or_out WHEN 'out' then amount ELSE 0 END as SAIDA, \n",
    "                                        CASE in_or_out WHEN  'in' then amount ELSE 0 END as ENTRADA,\n",
    "                                        DATE_PART('month', to_timestamp(CAST(completed_at as numeric)/1000)) MES\n",
    "                                        FROM fact_movements_table\n",
    "                                        WHERE (status = 'completed') AND (DATE_PART('year', to_timestamp(CAST(completed_at as numeric)/1000)) = 2020)) AS transactions\n",
    "                            GROUP BY mes, account_id\n",
    "                            ORDER BY mes, account_id\n",
    "\n",
    "\n",
    "''', engine)\n",
    "end = time.time()\n",
    "print(\"Time to query execution: \",end - start)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 112,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time to query execution:  0.6535401344299316\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    mes         account_id  entradas_total  saidas_total  balanco\n",
       "0   1.0   2569200459575096         6622.15       1826.30  4795.85\n",
       "1   1.0   2572645138169593         3314.38       1467.31  1847.07\n",
       "2   1.0   2969674447809961         9013.62       3569.48  5444.14\n",
       "3   1.0   5756422114496119         2926.91       2170.55   756.36\n",
       "4   1.0   5763135580788529         6460.05      11030.11 -4570.06\n",
       "5   1.0   6731171884115662         9660.82       5316.85  4343.97\n",
       "6   1.0   6754575908057409         5780.74          0.00  5780.74\n",
       "7   1.0   6759884497455352         4308.37       1542.19  2766.18\n",
       "8   1.0   7106839639082916         3062.88       1402.65  1660.23\n",
       "9   1.0   7399497589386025         1319.22          0.00  1319.22\n",
       "10  1.0   8390860978077109         7559.18      17064.75 -9505.57\n",
       "11  1.0   9682140161583058         6125.78      11087.89 -4962.11\n",
       "12  1.0  11972044772734216         4480.96        759.50  3721.46\n",
       "13  1.0  14823956517654278        11269.08       4940.66  6328.42\n",
       "14  1.0  14960923507500004         2365.23       4424.75 -2059.52\n",
       "15  1.0  16488801170250194         1382.95          0.00  1382.95\n",
       "16  1.0  17010643349938116         1446.35       1812.93  -366.58\n",
       "17  1.0  17352812883658752         8757.83      13354.52 -4596.69\n",
       "18  1.0  18661351842096488         1148.46       5642.76 -4494.30\n",
       "19  1.0  21312345113145264        10272.73       2697.03  7575.70"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mes</th>\n      <th>account_id</th>\n      <th>entradas_total</th>\n      <th>saidas_total</th>\n      <th>balanco</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>2569200459575096</td>\n      <td>6622.15</td>\n      <td>1826.30</td>\n      <td>4795.85</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>2572645138169593</td>\n      <td>3314.38</td>\n      <td>1467.31</td>\n      <td>1847.07</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>2969674447809961</td>\n      <td>9013.62</td>\n      <td>3569.48</td>\n      <td>5444.14</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>5756422114496119</td>\n      <td>2926.91</td>\n      <td>2170.55</td>\n      <td>756.36</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>5763135580788529</td>\n      <td>6460.05</td>\n      <td>11030.11</td>\n      <td>-4570.06</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.0</td>\n      <td>6731171884115662</td>\n      <td>9660.82</td>\n      <td>5316.85</td>\n      <td>4343.97</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.0</td>\n      <td>6754575908057409</td>\n      <td>5780.74</td>\n      <td>0.00</td>\n      <td>5780.74</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1.0</td>\n      <td>6759884497455352</td>\n      <td>4308.37</td>\n      <td>1542.19</td>\n      <td>2766.18</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1.0</td>\n      <td>7106839639082916</td>\n      <td>3062.88</td>\n      <td>1402.65</td>\n      <td>1660.23</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1.0</td>\n      <td>7399497589386025</td>\n      <td>1319.22</td>\n      <td>0.00</td>\n      <td>1319.22</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1.0</td>\n      <td>8390860978077109</td>\n      <td>7559.18</td>\n      <td>17064.75</td>\n      <td>-9505.57</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1.0</td>\n      <td>9682140161583058</td>\n      <td>6125.78</td>\n      <td>11087.89</td>\n      <td>-4962.11</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1.0</td>\n      <td>11972044772734216</td>\n      <td>4480.96</td>\n      <td>759.50</td>\n      <td>3721.46</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1.0</td>\n      <td>14823956517654278</td>\n      <td>11269.08</td>\n      <td>4940.66</td>\n      <td>6328.42</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1.0</td>\n      <td>14960923507500004</td>\n      <td>2365.23</td>\n      <td>4424.75</td>\n      <td>-2059.52</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1.0</td>\n      <td>16488801170250194</td>\n      <td>1382.95</td>\n      <td>0.00</td>\n      <td>1382.95</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1.0</td>\n      <td>17010643349938116</td>\n      <td>1446.35</td>\n      <td>1812.93</td>\n      <td>-366.58</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1.0</td>\n      <td>17352812883658752</td>\n      <td>8757.83</td>\n      <td>13354.52</td>\n      <td>-4596.69</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1.0</td>\n      <td>18661351842096488</td>\n      <td>1148.46</td>\n      <td>5642.76</td>\n      <td>-4494.30</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1.0</td>\n      <td>21312345113145264</td>\n      <td>10272.73</td>\n      <td>2697.03</td>\n      <td>7575.70</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "balance_new.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}