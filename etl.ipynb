{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# ETL Processes\n",
    "Use this notebook to develop the ETL process for each of your tables before completing the `etl.py` file to load the whole datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import psycopg2\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from sql_queries import *"
   ]
  },
  {
   "source": [
    "conn = psycopg2.connect(\"host=127.0.0.1 user=postgres password=nubank\")\n",
    "conn.set_session(autocommit=True)\n",
    "cur = conn.cursor()"
   ],
   "cell_type": "code",
   "metadata": {
    "editable": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ObjectInUse",
     "evalue": "database \"nubank\" is being accessed by other users\nDETAIL:  There are 3 other sessions using the database.\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mObjectInUse\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-da260512008f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DROP DATABASE IF EXISTS nubank\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CREATE DATABASE nubank WITH ENCODING 'utf8' TEMPLATE template0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# close connection to default database\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mObjectInUse\u001b[0m: database \"nubank\" is being accessed by other users\nDETAIL:  There are 3 other sessions using the database.\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"DROP DATABASE IF EXISTS nubank\")\n",
    "cur.execute(\"CREATE DATABASE nubank WITH ENCODING 'utf8' TEMPLATE template0\")\n",
    "\n",
    "# close connection to default database\n",
    "conn.close()    \n",
    "    \n",
    " # connect to sparkify database\n",
    "conn = psycopg2.connect(\"host=127.0.0.1 dbname=nubank user=postgres password=nubank\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "source": [
    "conn = psycopg2.connect(\"host=127.0.0.1 dbname=nubank user=postgres password=nubank\")\n",
    "cur = conn.cursor()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in drop_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "\n",
    "for query in create_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('accounts_table',), ('city_table',), ('costumers_table',), ('country_table',), ('d_month_table',), ('d_time_table',), ('d_week_table',), ('d_weekday_table',), ('d_year_table',), ('pix_movements_table',), ('state_table',), ('transfer_ins_table',), ('transfer_outs_table',)]\n"
     ]
    }
   ],
   "source": [
    "#VERIFY THE DB TABLES\n",
    "cur.execute(\"select relname from pg_class where relkind='r' and relname !~ '^(pg_|sql_)';\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_function(data, query):\n",
    "        for i, row in data.iterrows():\n",
    "                cur.execute(query, list(row))\n",
    "        conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Process table data\n",
    "In this first part, you'll perform ETL on the tables"
   ]
  },
  {
   "source": [
    "### Insert data in accounts_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_df = pd.read_csv(\"./tables/tables/accounts_table.csv\")\n",
    "insert_function(accounts_df, accounts_table_insert)"
   ]
  },
  {
   "source": [
    "### Insert data in city_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "city_df = pd.read_csv(\"./tables/tables/city_table.csv\")\n",
    "city_df = city_df[['city_id','city','state_id']]\n",
    "insert_function(city_df, city_table_insert)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 10,
   "outputs": []
  },
  {
   "source": [
    "### Insert data in costumers_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "costumers_df = pd.read_csv(\"./tables/tables/costumers_table.csv\")\n",
    "costumers_df.head()\n",
    "insert_function(costumers_df, costumers_table_insert)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 12,
   "outputs": []
  },
  {
   "source": [
    "### Insert data in country_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df = pd.read_csv(\"./tables/tables/country_table.csv\")\n",
    "country_df = country_df[[\"country_id\", \"country\"]]\n",
    "insert_function(country_df, country_table_insert)"
   ]
  },
  {
   "source": [
    "### Insert data in d_month_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_month_table_df = pd.read_csv(\"./tables/tables/d_month_table.csv\")\n",
    "insert_function(d_month_table_df, d_month_table_insert)"
   ]
  },
  {
   "source": [
    "### Insert data in d_time_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_time_table_df = pd.read_csv(\"./tables/tables/d_time_table.csv\")\n",
    "tmp_df = \"./tables/tables/tmp.csv\"\n",
    "d_time_table_df.to_csv(tmp_df,index=False , header=False)\n",
    "f = open(tmp_df, 'r')\n",
    "cur.copy_from(f, \"d_time_table\", sep=\",\")\n",
    "conn.commit()"
   ]
  },
  {
   "source": [
    "### Insert data in d_week_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "UniqueViolation",
     "evalue": "duplicate key value violates unique constraint \"d_week_table_pkey\"\nDETAIL:  Key (weekday_id)=(102414000) already exists.\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUniqueViolation\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-c3f6bcfbb0a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0md_week_table_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./tables/tables/d_week_table.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0minsert_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_week_table_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_week_table_insert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-b45ed2aad834>\u001b[0m in \u001b[0;36minsert_function\u001b[1;34m(data, query)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minsert_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                 \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#conn.close()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUniqueViolation\u001b[0m: duplicate key value violates unique constraint \"d_week_table_pkey\"\nDETAIL:  Key (weekday_id)=(102414000) already exists.\n"
     ]
    }
   ],
   "source": [
    "d_week_table_df = pd.read_csv(\"./tables/tables/d_week_table.csv\")\n",
    "insert_function(d_week_table_df, d_week_table_insert)"
   ]
  },
  {
   "source": [
    "### Insert data in d_weekday_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_weekday_table_df = pd.read_csv(\"./tables/tables/d_weekday_table.csv\")\n",
    "insert_function(d_weekday_table_df, d_weekday_table_insert)"
   ]
  },
  {
   "source": [
    "### Insert data in d_year_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_year_table_df = pd.read_csv(\"./tables/tables/d_year_table.csv\")\n",
    "insert_function(d_year_table_df, d_year_table_insert)"
   ]
  },
  {
   "source": [
    "### Insert data in state_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_table_df = pd.read_csv(\"./tables/tables/state_table.csv\")\n",
    "state_table_df = state_table_df[[\"state_id\", \"state\", \"country_id\"]]\n",
    "insert_function(state_table_df, state_table_insert)"
   ]
  },
  {
   "source": [
    "### Insert data in pix_movements_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_movements_table_df = pd.read_csv(\"./tables/tables/pix_movements_table.csv\")\n",
    "pix_movements_table_df\n",
    "\n",
    "tmp_df = \"./tables/tables/tmp.csv\"\n",
    "pix_movements_table_df.to_csv(tmp_df,index=False , header=False)\n",
    "f = open(tmp_df, 'r')\n",
    "cur.copy_from(f, \"pix_movements_table\", sep=\",\")\n",
    "conn.commit()"
   ]
  },
  {
   "source": [
    "### Insert data in transfer_ins_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_ins_table_df = pd.read_csv(\"./tables/tables/transfer_ins_table.csv\")\n",
    "tmp_df = \"./tables/tables/tmp.csv\"\n",
    "transfer_ins_table_df.to_csv(tmp_df,index=False , header=False)\n",
    "f = open(tmp_df, 'r')\n",
    "cur.copy_from(f, \"transfer_ins_table\", sep=\",\")\n",
    "conn.commit()"
   ]
  },
  {
   "source": [
    "### Insert data in transfer_outs_table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_outs_table_df = pd.read_csv(\"./tables/tables/transfer_outs_table.csv\")\n",
    "tmp_df = \"./tables/tables/tmp.csv\"\n",
    "transfer_outs_table_df.to_csv(tmp_df,index=False , header=False)\n",
    "f = open(tmp_df, 'r')\n",
    "cur.copy_from(f, \"transfer_outs_table\", sep=\",\")\n",
    "conn.commit()"
   ]
  },
  {
   "source": [
    "### Close connection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "source": [
    "# Answering the questions: "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. Create a SQL query to help Jane retrieving the monthly balance of all accounts (this query should be made using the warehouse structure before the changes you propose on 2.)\n",
    "\n",
    "Your colleague Jane Hopper, the analyst in charge of analysing customer behaviour, who directly\n",
    "consumes data from the Data Warehouse Environment, needs to get all the account's monthly\n",
    "balances between Jan/2020 and Dec/2020. She wasn't able to do it alone, and asked for your help.\n",
    "Add to your resolution the SQL query used to retrieve the data needed (the necessary tables in csv\n",
    "format were sent along with this pdf, on folder tables/). Feel free to use the dialect of your choice,\n",
    "but please specify the SQL engine.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Resolution:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Developing the query to Account Monthly Balance\n",
    "\n",
    "The original table schema has three tables that contain movements in the costumers accounts, so in order to help Jane I need to put it all together and create the expected columns in the figure bellow.\n",
    "\n",
    "![](./images/balance_table.jpg)\n",
    "\n",
    "Note: In the image above the column costumer is present, but Jane want to know the account balance so to do this the account_id column will be used insteade costumer column.\n",
    "\n",
    "\n",
    "1. Using the `UNION ALL` combined with `SELECT` the result put all the data contained in the tables together one appending the tables creating a subquery.\n",
    "2. We need to create the columns with INs and OUTs, in the pix transactions we have to distinct between the IN and OUT movements, where I used `CASE` to make this distinction using the column `in_or_out` present in the pix table:\n",
    "\n",
    "\n",
    "```sql \n",
    "    CASE in_or_out WHEN 'pix_out' then pix_amount ELSE 0 END as SAIDA,\n",
    "    CASE in_or_out WHEN  'pix_in' then pix_amount ELSE 0 END as ENTRADA\n",
    "``` \n",
    "In the tables of usual transactions the distinction was not necessary, because each table contain one specific kind of transaction, so I returned the amount in the column that represents the kind of transaction and 0(zero) in the other column, like above:\n",
    "\n",
    "In table:\n",
    "```sql\n",
    "        SELECT account_id,\n",
    "        0 AS SAIDA, \n",
    "        amount as ENTRADA,\n",
    "```\n",
    "\n",
    "Out table:\n",
    "```sql\n",
    "        SELECT account_id,\n",
    "        amount as SAIDA,\n",
    "        0 AS ENTRADA,\n",
    "```\n",
    "\n",
    "3. To get the mounth column, first I converted the timestamp that contains the date when the transaction was completed to a datetime format and after with `DATE_PART` specifing month as my part of interest, I got the month:\n",
    "\n",
    "```sql\n",
    "        DATE_PART('month', to_timestamp(CAST(transaction_completed_at as numeric)/1000)) MES\n",
    "```\n",
    "\n",
    "4. The `WHERE` clause is filtering the transactions that were completed and occured between JAN/2020 and DEC/2020:\n",
    "\n",
    "```sql\n",
    "        WHERE (status = 'completed') AND (DATE_PART('year', to_timestamp(CAST(pix_completed_at as numeric)/1000))  = 2020)\n",
    "```\n",
    "\n",
    "5. With the data returned in the subquery `transactions` is necessary to sum all the In and all the Out movements separately grouping then by account_id and month, after the monthly balance is a result of the Ins - Outs for each month and account. All this columns were rounded with two decimal places that is enough when we talk about monetary values.\n",
    "\n",
    "\n",
    "Select statement:\n",
    "```sql\n",
    "        SELECT CAST(mes AS INT), account_id,\n",
    "        ROUND(CAST(sum(entrada) AS NUMERIC),2) AS entradas_total,\n",
    "        ROUND(CAST(SUM(saida) AS NUMERIC),2) as saidas_total,\n",
    "        ROUND(CAST((sum(entrada) - SUM(saida))AS NUMERIC),2) as balanco\n",
    "\n",
    "```\n",
    "\n",
    "Group by and Order by statement:\n",
    "\n",
    "```sql\n",
    "        GROUP BY mes, account_id\n",
    "        ORDER BY account_id, mes\n",
    "\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Importing the `create_engine` from `sqlalchemy` to create the connection to our Postgres database."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://postgres:nubank@127.0.0.1/nubank')"
   ]
  },
  {
   "source": [
    "### Using the `pd.read_sql` and the previous created `engine` to execute our SQL query and create a pandas dataframe with the result."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance = pd.read_sql('''\n",
    "SELECT CAST(mes AS INT), account_id,\n",
    "ROUND(CAST(sum(entrada) AS NUMERIC),2) AS entradas_total,\n",
    "ROUND(CAST(SUM(saida) AS NUMERIC),2) as saidas_total,\n",
    "ROUND(CAST((sum(entrada) - SUM(saida))AS NUMERIC),2) as balanco\n",
    "FROM (  SELECT account_id, \n",
    "        CASE in_or_out WHEN 'pix_out' then pix_amount ELSE 0 END as SAIDA, \n",
    "        CASE in_or_out WHEN  'pix_in' then pix_amount ELSE 0 END as ENTRADA,\n",
    "        DATE_PART('month', to_timestamp(CAST(pix_completed_at as numeric)/1000)) MES\n",
    "        FROM pix_movements_table\n",
    "        WHERE (status = 'completed') AND (DATE_PART('year', to_timestamp(CAST(pix_completed_at as numeric)/1000))  = 2020)\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        SELECT account_id,\n",
    "        0 AS SAIDA, \n",
    "        amount as ENTRADA,\n",
    "        DATE_PART('month', to_timestamp(CAST(transaction_completed_at as numeric)/1000)) MES\n",
    "        FROM transfer_ins_table\n",
    "        WHERE (status = 'completed') AND (DATE_PART('year', to_timestamp(CAST(transaction_completed_at as numeric)/1000)) = 2020)\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        SELECT account_id,\n",
    "        amount as SAIDA,\n",
    "        0 AS ENTRADA,\n",
    "        DATE_PART('month', to_timestamp(CAST(transaction_completed_at as numeric)/1000)) MES\n",
    "        FROM transfer_outs_table\n",
    "        WHERE (status = 'completed') AND (DATE_PART('year', to_timestamp(CAST(transaction_completed_at as numeric)/1000)) = 2020)) as transactions\n",
    "GROUP BY mes, account_id\n",
    "ORDER BY account_id, mes\n",
    "''', engine)"
   ]
  },
  {
   "source": [
    "### Getting informations about the created pandas dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 45557 entries, 0 to 45556\nData columns (total 5 columns):\n #   Column          Non-Null Count  Dtype  \n---  ------          --------------  -----  \n 0   mes             45557 non-null  int64  \n 1   account_id      45557 non-null  int64  \n 2   entradas_total  45557 non-null  float64\n 3   saidas_total    45557 non-null  float64\n 4   balanco         45557 non-null  float64\ndtypes: float64(3), int64(2)\nmemory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "balance.info()"
   ]
  },
  {
   "source": [
    "### Looking into the `balance` dataframe to see the result of our query"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    mes        account_id  entradas_total  saidas_total  balanco\n",
       "0     1  2569200459575096         6622.15       1826.30  4795.85\n",
       "1     2  2569200459575096         2510.59       4934.91 -2424.32\n",
       "2     3  2569200459575096         2221.55       3205.17  -983.62\n",
       "3     4  2569200459575096         4492.74        540.40  3952.34\n",
       "4     5  2569200459575096         1825.52       2429.55  -604.03\n",
       "5     6  2569200459575096         2322.68       3059.74  -737.06\n",
       "6     7  2569200459575096         3003.19       8062.59 -5059.40\n",
       "7     8  2569200459575096           80.60       2333.27 -2252.67\n",
       "8     9  2569200459575096         2401.67       3796.14 -1394.47\n",
       "9    10  2569200459575096         1542.31        457.52  1084.79\n",
       "10   11  2569200459575096          253.42       5605.24 -5351.82\n",
       "11   12  2569200459575096         7881.35       3179.07  4702.28\n",
       "12    1  2572645138169593         3314.38       1467.31  1847.07\n",
       "13    2  2572645138169593         3027.06       1032.80  1994.26\n",
       "14    3  2572645138169593         1491.24       6602.16 -5110.92\n",
       "15    4  2572645138169593            0.00       1556.52 -1556.52\n",
       "16    5  2572645138169593         2426.07       4344.24 -1918.17\n",
       "17    6  2572645138169593            0.00       2282.97 -2282.97\n",
       "18    7  2572645138169593         3051.84        959.94  2091.90\n",
       "19    8  2572645138169593          794.32       2953.02 -2158.70"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mes</th>\n      <th>account_id</th>\n      <th>entradas_total</th>\n      <th>saidas_total</th>\n      <th>balanco</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2569200459575096</td>\n      <td>6622.15</td>\n      <td>1826.30</td>\n      <td>4795.85</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2569200459575096</td>\n      <td>2510.59</td>\n      <td>4934.91</td>\n      <td>-2424.32</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>2569200459575096</td>\n      <td>2221.55</td>\n      <td>3205.17</td>\n      <td>-983.62</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>2569200459575096</td>\n      <td>4492.74</td>\n      <td>540.40</td>\n      <td>3952.34</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>2569200459575096</td>\n      <td>1825.52</td>\n      <td>2429.55</td>\n      <td>-604.03</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>2569200459575096</td>\n      <td>2322.68</td>\n      <td>3059.74</td>\n      <td>-737.06</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>2569200459575096</td>\n      <td>3003.19</td>\n      <td>8062.59</td>\n      <td>-5059.40</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>2569200459575096</td>\n      <td>80.60</td>\n      <td>2333.27</td>\n      <td>-2252.67</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>2569200459575096</td>\n      <td>2401.67</td>\n      <td>3796.14</td>\n      <td>-1394.47</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>2569200459575096</td>\n      <td>1542.31</td>\n      <td>457.52</td>\n      <td>1084.79</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>2569200459575096</td>\n      <td>253.42</td>\n      <td>5605.24</td>\n      <td>-5351.82</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>2569200459575096</td>\n      <td>7881.35</td>\n      <td>3179.07</td>\n      <td>4702.28</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1</td>\n      <td>2572645138169593</td>\n      <td>3314.38</td>\n      <td>1467.31</td>\n      <td>1847.07</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2</td>\n      <td>2572645138169593</td>\n      <td>3027.06</td>\n      <td>1032.80</td>\n      <td>1994.26</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>3</td>\n      <td>2572645138169593</td>\n      <td>1491.24</td>\n      <td>6602.16</td>\n      <td>-5110.92</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>4</td>\n      <td>2572645138169593</td>\n      <td>0.00</td>\n      <td>1556.52</td>\n      <td>-1556.52</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>5</td>\n      <td>2572645138169593</td>\n      <td>2426.07</td>\n      <td>4344.24</td>\n      <td>-1918.17</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>6</td>\n      <td>2572645138169593</td>\n      <td>0.00</td>\n      <td>2282.97</td>\n      <td>-2282.97</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>7</td>\n      <td>2572645138169593</td>\n      <td>3051.84</td>\n      <td>959.94</td>\n      <td>2091.90</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>8</td>\n      <td>2572645138169593</td>\n      <td>794.32</td>\n      <td>2953.02</td>\n      <td>-2158.70</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "balance.head(20)"
   ]
  },
  {
   "source": [
    "## 2. Improve the data warehouse architecture and justify your changes\n",
    "\n",
    "Imagine now that you could remodel the data warehouse environment freely, keeping in mind that\n",
    "Nubank is always evolving with new products (Whatsapp Payments, PIX, phone recharge, etc) and it\n",
    "is also expanding to new countries, so our data warehouse needs to accommodate all these\n",
    "incoming changes. Which modifications would you propose and why? Remember to consider that\n",
    "other analysts will be using the same structure, so it should be as clear as possible. Feel free to\n",
    "change, remove or add tables/fields to generate a better database design"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}